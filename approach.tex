\section{Approach}
\label{sec:pipeline}
\begin{figure*} 
	\centering
	\input{images/pipeline.pdf_tex}
	\caption{A high level overview of our surface reconstruction pipeline in 2D. On the far left, a) shows the initial point-set. b) is the result of the smoothed variational reconstruction of the gradient of the indicator, the top image is the x component, the bottom is the y component. The approximate divergence of the smoothed indicator function is c), and d) is the resulting indicator function. }
	\label{fig:pipeline}
\end{figure*}

A high level description of our approach is outlined in \FG{fig:pipeline}. From the oriented surface samples, we construct the approximation $\vec{V}(\vx)$ using our variational formulation. We then apply FIR filters to the coefficients of the approximation to construct a scalar field representing the approximate divergence of the smoothed normal field (\FG{fig:pipeline}c.) We then use an appropriate discretization of the inverse Laplacian operator to solve the Poisson equation \EQ{eq:poisson}, and obtain a smooth function that approximates the original indicator function (\FG{fig:pipeline}c). Our code is also freely available for download.


\subsection{Obtaining the smoothed vector field} \label{sec:getting_vd}
\label{sec:obtainingV}
We define the vector field as $\vec{V}(\vx):=\mathbf{L} \left[\upsilon_1(\vx) \ \upsilon_2(\vx) \ \upsilon_3(\vx)\right]^T$ where $\mathbf{L := [b_1 \ b_2 \ b_3]}$ is a basis for $\realn^3$ that contains the principal lattice directions of the chosen lattice. Each $\upsilon_i$ is a scalar function representing the projection of the smoothed normal field onto each respective principal lattice direction $\mathbf{b}_i$. This may seem unintuitive at first, however, using a non-canonical basis to represent $\vec{V}$ will be convenient in two ways. Firstly, it will allow us to approximate the divergence of $\vec{V}$ by taking directional derivatives of $\vec{V}$ in the principal lattice directions. This is motivated by the fact that it is more natural to approximate derivatives in the principal lattice directions on non-Cartesian lattices. Secondly, it will allow us to construct divergence of the smoothed normal field from more than three principal lattice directions. We also allow each function $\upsilon_i$ to potentially be represented in different function spaces, i.e. {\small 
\begin{equation} 
	\upsilon_i(\vx) = \sum_{k=0}^N \text{v}_k^i \varphi_k^i(\vx) \in \aspace{\lattice{L}}{\varphi^i}.
\end{equation}}
The coefficient vector of $\upsilon_i$ is denoted as $\mathbf{v}_i:=\left[\text{v}_1^i \ \cdots \ \text{v}_N^i \right]$.We use the unfortunate notation $\text{v}_j^i, \varphi_k^i$ to denote that those objects belong to $\upsilon_i(x)$, not to denote exponentiation. We consider each component of $\vec{V}(\vx)$ separately, thus, it suffices to describe the process at one $\upsilon_i$. We simply find the $\upsilon_i$ that minimizes {\small 
\begin{equation} \label{eq:vari_eqn}
 	\sump_{\forall (\vx,\vn) \in P }^{M} (\upsilon_i(\vx) - (\mathbf{L}^{-1})_i \cdot \vect{n})^2 + E(\upsilon_i).
\end{equation} }
Where $(\mathbf{L}^{-1})_i$ is the $i^{th}$ column of $(\mathbf{L}^{-1}).$ As before, this provides us with a parametrized way of controlling the smoothness of the resulting approximation, without the need to explicitly choose a smoothing kernel. These $\mathbf{v}_i$ can be obtained using the procedure of \SC{sec:vari_review}.


\subsection{Divergence of the Smoothed Vector Field}
\label{sec:divergence}
A simple way to obtain the divergence of $\vec{V}(\vx)$ is to consider its analytical partial derivatives which, due to the linearity of the expression, requires one to only take the analytic partial derivatives of the underlying kernel functions. However, this reduces the smoothness of the solution \cite{zahgrad}, and there is also no conclusive evidence that suggests the analytic derivative of the kernel provides a better approximation to true underlying derivative. With this in mind, we choose to take a discrete filtering approach and approximate the divergence of $\vec{V}$ with a set of discrete FIR filters. While these filters do not strictly facilitate the best approximation scheme for derivatives, they provide a good compromise between compactness versus accuracy, even more so when the reconstruction spaces are shifted \cite{gradrev}. 

\subsubsection{Spaces Spanned by a Single Generating Function}
When each space is identical (when $\upsilon_i \in \aspace{\lattice{L}_h}{\varphi}$) the divergence can be found by taking directional derivatives of $\vec{V}$ along the vectors in $\mathbf{L}$ as follows: {\small 
\begin{eqnarray}\label{eq:div_dir}
	\grad \cdot \vec{V}(\vx) & = & \grad \cdot \mathbf{L} \left[\upsilon_1(\vx) \ \upsilon_2(\vx) \ \upsilon_3(\vx)\right]^T \notag \\
	 & = & \left[ \mathbf{(\grad \cdot b_1) \ (\grad \cdot b_2) \ (\grad \cdot b_3 ) }\right] \cdot \left[\upsilon_1 \ \upsilon_2 \ \upsilon_3\right]^T \\
	 & = & \dv{\mathbf{b_1}}\upsilon_1 + \dv{\mathbf{b_2}}\upsilon_2 + \dv{\mathbf{b_3}}\upsilon_3. \notag
\end{eqnarray} }
This allows us to approximate the divergence of $\vec{V}$ by simply convolving the coefficient vector corresponding to $\upsilon_i$ with an appropriate 1D derivative filter $d[n]$, then sum the coefficients. The expression for the resulting coefficient vector of the divergence is then {\small
\begin{equation}
	\mathbf{f}:= \sum_{i=1}^3{ \mathbf{v}_i*\mathbf{d}_i}
\label{eq:divergenceViaFiltering}
\end{equation}}
where $\mathbf{d}_i$ is a directional derivative filter obtained by orienting the 1D filter $d$ along the direction $\mathbf{b}_i.$ 

\subsubsection{Shifted Reconstruction Spaces}
To reconstruct within a shifted space, the input point-set is shifted by $\frac{1}{2}\mathbf{b_i}$ then reconstructed within $\fspce{\varphi}{L}$. This is clearly equivalent to reconstructing in a shifted basis space, however, care must be taken to ensure that the data are brought back to a centered representation. Our choice of a shifted derivative filter $s[n]$ accounts for this and brings the resulting approximation back to the unshifted space. Both the shifted and unshifted filters we utilize are found in \TA{tab:filters} and are chosen so that they provide a fourth-order discretization of the 1D derivative operator~\cite{gradrev}. 

\subsubsection{Four Direction Divergence on the BCC Lattice}
It is also possible to consider a basis $\mathbf{L}$ in which we choose more than three principal directions to reconstruct the divergence. Thus, we may choose $\mathbf{L} = \mathbf{\Xii_{B}} $ as the basis for our function. To accommodate for this, we redefine $\vec{V}(\vx):=\mathbf{L} \left[\upsilon_1 \ \upsilon_2 \ \upsilon_3 \ \upsilon_4 \right.]^T$ Since this matrix is not square, it is not possible to take its inverse in \EQ{eq:vari_eqn}. Instead, the least norm inverse $\mathbf{L^T(LL}^T\mathbf{)}^{-1}$ is used. It is easy to see that, by the same reasoning as in equation \EQ{eq:div_dir}, $\grad \cdot \vec{V} = \dv{\mathbf{b_1}}\upsilon_1 + \dv{\mathbf{b_2}}\upsilon_2 + \dv{\mathbf{b_3}}\upsilon_3 + \dv{\mathbf{b_4}}\upsilon_4$. Thus, we may use the same idea as in the three direction case, approximating each direction separately, and summing the coefficients to obtain an approximation to the divergence (the shifted case is also similar).
